--%comparator=tech.mlsql.it.IgnoreResultComparator

-- create test data
set jsonStr='''
{"features":[5.1,3.5,1.4,0.2],"label":0.0},
{"features":[5.1,3.5,1.4,0.2],"label":1.0}
{"features":[5.1,3.5,1.4,0.2],"label":0.0}
{"features":[4.4,2.9,1.4,0.2],"label":0.0}
{"features":[5.1,3.5,1.4,0.2],"label":1.0}
{"features":[5.1,3.5,1.4,0.2],"label":0.0}
{"features":[5.1,3.5,1.4,0.2],"label":0.0}
{"features":[4.7,3.2,1.3,0.2],"label":1.0}
{"features":[5.1,3.5,1.4,0.2],"label":0.0}
{"features":[5.1,3.5,1.4,0.2],"label":0.0}
''';
load jsonStr.`jsonStr` as data;
select vec_dense(features) as features , label as label from data
as data1;

-- select * from data1 as output1;
-- -- use RandomForest
train data1 as LinearRegression.`/tmp/model` where

-- -- once set true,every time you run this script, MLSQL will generate new directory for you model
keepVersion="true"

-- specicy the test dataset which will be used to feed evaluator to generate some metrics e.g. F1, Accurate
and evaluateTable="data1"

-- specify group 0 parameters
and `fitParam.0.labelCol`="label"
and `fitParam.0.featuresCol`="features"
and `fitParam.0.elasticNetParam`="0.1"

-- specify group 1 parameters
and `fitParam.1.featuresCol`="features"
and `fitParam.1.labelCol`="label"
and `fitParam.1.elasticNetParam`="0.7"
as model_result;

select name,value from model_result where name="status" as result;
-- make sure status of  all models are success.
!assert result ''':value=="success"'''  "all model status should be success";
predict data1 as LinearRegression.`/tmp/model`;
register LinearRegression.`/tmp/model` as lr_predict;
select lr_predict(features) as predict_label, label from data1 as output;